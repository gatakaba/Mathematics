ベイズで見るコイン投げ
========================
ベイズ推定は観測したデータから仮説に対する確率を更新してゆく手法である。
例えば、鍵をなくしてしまった状況を考えよう。
この時、下駄箱や服の中など見つかりそうな箇所にあたりを付けて
それぞれの箇所に確率を割り振り、確率が高い順に鍵があるか確かめるのが一般的ではないか。
そして鍵が見つからなかった場合、探索した箇所にある確率を0として、他の箇所の確率を割り当て直す。
このように仮説(=i番目にある)に確率を割り当てて、
観測(=情報)によって仮説の確率(=信念)を更新してゆく手法をベイズ推定と呼ぶ。
頻度主義に基づく推定とベイズ理論に基づく推定において最も異なる点は、
仮説を確率的に見るかどうかという点だ。

コイン投げを例に考えてみよう。
ここでコインを何回か投げて表が出る確率μを推定する。
頻度主義においては単純にμ=表が出た回数/コインを投げた回数となるが、
ベイズ推定では、μを確率分布とみなして、P(μ|表が出た回数)を推定する。

ベイズの定理は確率論の基本的な法則である
加法定理
P(X)=Σ_Y P(X,Y)
乗法定理
P(X,Y)=P(Y|X)P(X)
を組み合わせることによって直ちに導出することができ、その式は
P(Y|X)=P(X|Y)P(Y)/P(X)
となり別段特別なものではなく、この公式は頻度主義による手法も使われている。
大事なことは、推定したい仮説やパラメータを確率変数とみなすかみなさないかという考え方なのだ。

今回はコイン投げという事象を観測して、コインが表がでる確率μの確率密度がどのように変化していくかを見ていくことにする。

最初にコインを投げて表がでる確率をμ(0<=μ<=1)
表が出るという事象を使ってx=1,裏が出る事象をx=0とする。
これを定式化すると
p(x=1|μ)=μ
p(x=0|μ)=1-μ
まとめると、
p(x|μ)=μ^x*(1-μ)^(1-x)
となる。

ここで、コインをN回投げた時の観測データ
D={x1,・・・・,xN}
が得られたとする。
p(D|μ)=Π^N_{n=1} p(x_n|μ)=Π^N_{n=1}(μ^xn*(1-μ)^(1-xn))
mは表が出た回数,nは裏が出た回数とすると、
p(μ|D)=P(D|μ)*P(μ)/p(D)=beta(μ|m+1,n+1)
と表せる。
ここでbetaはベータ関数である。
事前確率分布は一様分布とした。(図1参照)
(図2)に表が出る確率が0.5における遷移図を示す。
±標準偏差*2の区間を薄く塗りつぶした。

コインが出る目を観測数が増えるほど、確率分布の形状は正規分布に近づき標準偏差は減少する。
そして確率分布の期待値は0.5に近づく。

参考のため図3に表がでる確率を0.25とした時の確率分布を示す。

ベイズ推定は計算量は増えるが、頻度主義により手法に比べて尤もな結果が得られる。
頻度主義の手法では三回投げて三回表がでた場合、裏がでる確率は0となってしまい、
この推論によると今後裏が出ることがないという主張になる。
ベイズ推定ではこのように極端な結果になることはない。
また変数を確率変数とみなすことによって、より複雑な階層的な統計モデル
と連結してより柔軟な推定ができる。



使ったプログラムはここにおいておきますね。
https://bitbucket.org/kaba32/tsubaki/src/783424d3bb365aaf752b846cbcbefe21a12eb933/src/Bayes/AssumeCoinProbability.py?at=master

